{
 "metadata": {
  "kernelspec": {
   "display_name": "Snowpark",
   "language": "python",
   "name": "snowpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "lastEditStatus": {
   "notebookId": "3gu27s6nem7w4sxvxqu4",
   "authorId": "726488193010",
   "authorName": "VISHALPRASANNA11",
   "authorEmail": "prasanna.vi@northeastern.edu",
   "sessionId": "7bf52a02-4542-46a7-9989-3efd5ec014d1",
   "lastEditTime": 1740850695084
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# Cryptocurrency Data Pipeline - Task Orchestration & Automation\n",
    "\n",
    "This notebook implements the task orchestration layer for the cryptocurrency data pipeline, automating the flow from data ingestion through harmonization to analytics."
   ],
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "## Setup Environment"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "id": "21e1d693-f727-4a80-84ba-d620033dd778",
   "metadata": {
    "language": "python",
    "name": "cell27",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nsession = Session.builder.getOrCreate()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- %%sql\nUSE ROLE CRYPTO_ROLE;\nUSE WAREHOUSE CRYPTO_WH;\nUSE SCHEMA CRYPTO_DB.HARMONIZED_CRYPTO;",
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell4"
   },
   "source": [
    "## Create Tasks for Pipeline Automation\n",
    "\n",
    "### 1. Data Ingestion Task - Runs every 4 hours to fetch new data"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "id": "61dd55ae-696e-4fc9-8880-045343b06933",
   "metadata": {
    "language": "sql",
    "name": "cell28",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_DATA_SP()\nRETURNS VARIANT\nLANGUAGE JAVASCRIPT\nAS\n$$\ntry {\n  // RapidAPI configuration\n  // Use Snowflake's secrets properly\n  var stmt = snowflake.createStatement({\n    sqlText: \"SELECT SECRET$GET_SECRET('CRYPTO_API_SECRET', 'PASSWORD')\"\n  });\n  var result = stmt.execute();\n  result.next();\n  var RAPIDAPI_KEY = result.getColumnValue(1);\n  \n  const RAPIDAPI_HOST = \"apidojo-yahoo-finance-v1.p.rapidapi.com\";\n\n  // S3 configuration \n  const S3_BUCKET = 'damg7245-crypto';\n  const S3_PREFIX = 'raw_data/';\n\n  // Get AWS credentials from secrets\n  stmt = snowflake.createStatement({\n    sqlText: \"SELECT SECRET$GET_SECRET('CRYPTO_AWS_CREDENTIALS', 'SECRET_STRING')\"\n  });\n  result = stmt.execute();\n  result.next();\n  var AWS_CREDS_STRING = result.getColumnValue(1);\n  var AWS_CREDS = JSON.parse(AWS_CREDS_STRING);\n  \n  var AWS_ACCESS_KEY = AWS_CREDS.ACCESS_KEY_ID;\n  var AWS_SECRET_KEY = AWS_CREDS.SECRET_ACCESS_KEY;\n  var AWS_REGION = AWS_CREDS.REGION;\n\n  // Crypto symbols to fetch\n  const CRYPTO_SYMBOLS = [\n    {symbol: 'BTC-USD', table: 'BTC'},\n    {symbol: 'ETH-USD', table: 'ETH'},\n    {symbol: 'DOGE-USD', table: 'DOGE'}\n  ];\n\n  // Create a temporary stage with direct AWS credentials\n  var createTempStageStmt = snowflake.createStatement({\n    sqlText: `\n      CREATE OR REPLACE TEMPORARY STAGE TEMP_CRYPTO_STAGE\n      URL = 's3://${S3_BUCKET}/'\n      CREDENTIALS = (AWS_KEY_ID = '${AWS_ACCESS_KEY}' AWS_SECRET_KEY = '${AWS_SECRET_KEY}')\n      FILE_FORMAT = (TYPE = CSV, SKIP_HEADER = 1)\n    `\n  });\n  createTempStageStmt.execute();\n\n  var results = {\n    status: 'success',\n    details: {},\n    error: null\n  };\n  \n  // Process each cryptocurrency\n  for (const crypto of CRYPTO_SYMBOLS) {\n    // Fetch data from RapidAPI\n    const data = fetchCryptoData(crypto.symbol, RAPIDAPI_KEY, RAPIDAPI_HOST);\n    \n    // Format data as CSV\n    const csvData = formatCsvData(data);\n    \n    // File name pattern matching the existing files\n    const fileName = `${crypto.table}_raw_daily.csv`;\n    const s3Path = S3_PREFIX + fileName;\n    \n    // Update the S3 file\n    const s3Result = updateS3File(csvData, s3Path);\n    \n    // Load data directly into Snowflake table\n    const loadResult = loadIntoRawTable(data, crypto.table);\n    \n    // Record results\n    results.details[crypto.symbol] = {\n      s3Updated: s3Result,\n      dbUpdated: loadResult\n    };\n  }\n  \n  return results;\n  \n} catch (error) {\n  return {\n    status: 'error',\n    message: error.message,\n    stack: error.stack\n  };\n}\n\n// Function to fetch crypto data from RapidAPI\nfunction fetchCryptoData(symbol, apiKey, apiHost) {\n  // Create SQL statement to execute HTTP request via Snowflake\n  const stmt = snowflake.createStatement({\n    sqlText: `\n      SELECT SYSTEM$HTTPGET(\n        'https://${apiHost}/market/get-quotes',\n        ARRAY_CONSTRUCT(\n          OBJECT_CONSTRUCT('name', 'x-rapidapi-key', 'value', '${apiKey}'),\n          OBJECT_CONSTRUCT('name', 'x-rapidapi-host', 'value', '${apiHost}')\n        ),\n        ARRAY_CONSTRUCT(\n          OBJECT_CONSTRUCT('name', 'region', 'value', 'US'),\n          OBJECT_CONSTRUCT('name', 'symbols', 'value', '${symbol}')\n        )\n      ) as response\n    `\n  });\n  \n  // Execute statement and get results\n  const result = stmt.execute();\n  result.next();\n  const response = JSON.parse(result.getColumnValue(1));\n  \n  // Extract and transform required fields\n  const now = new Date();\n  // Format date as YYYY-MM-DD 19:00:00\n  const timestamp = now.getUTCFullYear() + '-' + \n                   String(now.getUTCMonth() + 1).padStart(2, '0') + '-' + \n                   String(now.getUTCDate()).padStart(2, '0') + ' 19:00:00';\n  const quoteData = response.quoteResponse.result[0];\n  \n  return {\n    date: timestamp,\n    open: quoteData.regularMarketOpen,\n    high: quoteData.regularMarketDayHigh,\n    low: quoteData.regularMarketDayLow,\n    close: quoteData.regularMarketPrice,\n    volume: quoteData.regularMarketVolume,\n    adjclose: quoteData.regularMarketPrice // Using regularMarketPrice as adjclose\n  };\n}\n\n// Function to format CSV header and data\nfunction formatCsvData(data) {\n  const header = \"date,open,high,low,close,volume,adjclose\";\n  const row = `${data.date},${data.open},${data.high},${data.low},${data.close},${data.volume},${data.adjclose}`;\n  return header + \"\\n\" + row;\n}\n\n// Function to update S3 file\nfunction updateS3File(csvData, s3Path) {\n  try {\n    // First try to read existing data if available\n    const readExistingStmt = snowflake.createStatement({\n      sqlText: `\n        SELECT $1 as content\n        FROM @TEMP_CRYPTO_STAGE/${s3Path}\n      `\n    });\n    \n    let existingData = \"\";\n    try {\n      const result = readExistingStmt.execute();\n      while (result.next()) {\n        existingData += result.getColumnValue(1) + \"\\n\";\n      }\n    } catch (e) {\n      // If file doesn't exist or can't be read, we'll create a new one\n      // Just use the header + new row\n    }\n    \n    // If we have existing data, append new data to it (minus the header)\n    let finalData;\n    if (existingData && existingData.trim().length > 0) {\n      // Split the new CSV data to get just the row (skip header)\n      const newRow = csvData.split(\"\\n\")[1];\n      // Check if the date already exists in the data\n      const date = newRow.split(\",\")[0];\n      \n      // Simple check to avoid duplicating today's data\n      if (existingData.includes(date)) {\n        // Date already exists, no need to update\n        return { status: 'skipped', message: 'Data for today already exists' };\n      } else {\n        // Add the new row to existing data\n        finalData = existingData.trim() + \"\\n\" + newRow;\n      }\n    } else {\n      // No existing data, use the full CSV including header\n      finalData = csvData;\n    }\n    \n    // Create temporary file with the data\n    const tmpFile = \"/tmp/crypto_data_\" + Math.random().toString(36).substring(7) + \".csv\";\n    const writeFileStmt = snowflake.createStatement({\n      sqlText: `CALL SYSTEM$FILE_WRITE('${tmpFile}', '${finalData}')`\n    });\n    writeFileStmt.execute();\n    \n    // Upload to S3\n    const putStmt = snowflake.createStatement({\n      sqlText: `\n        PUT file://${tmpFile} @TEMP_CRYPTO_STAGE/${s3Path}\n        OVERWRITE = TRUE\n      `\n    });\n    putStmt.execute();\n    \n    // Clean up temporary file\n    const cleanupStmt = snowflake.createStatement({\n      sqlText: `CALL SYSTEM$FILE_DELETE('${tmpFile}')`\n    });\n    cleanupStmt.execute();\n    \n    return { status: 'success', path: s3Path };\n  } catch (error) {\n    return { status: 'error', message: error.message };\n  }\n}\n\n// Function to load data directly into the raw table\nfunction loadIntoRawTable(data, tableName) {\n  try {\n    // Check if we already have data for this date\n    const checkStmt = snowflake.createStatement({\n      sqlText: `\n        SELECT COUNT(1) FROM CRYPTO_DB.RAW_CRYPTO.${tableName}\n        WHERE date = '${data.date}'\n      `\n    });\n    const checkResult = checkStmt.execute();\n    checkResult.next();\n    const count = checkResult.getColumnValue(1);\n    \n    if (count > 0) {\n      // Data for this date already exists, update it\n      const updateStmt = snowflake.createStatement({\n        sqlText: `\n          UPDATE CRYPTO_DB.RAW_CRYPTO.${tableName}\n          SET open = ${data.open},\n              high = ${data.high},\n              low = ${data.low},\n              close = ${data.close},\n              volume = ${data.volume},\n              adjclose = ${data.adjclose},\n              ingestion_timestamp = CURRENT_TIMESTAMP()\n          WHERE date = '${data.date}'\n        `\n      });\n      updateStmt.execute();\n      return { status: 'updated', date: data.date };\n    } else {\n      // Insert new record\n      const insertStmt = snowflake.createStatement({\n        sqlText: `\n          INSERT INTO CRYPTO_DB.RAW_CRYPTO.${tableName}\n          (date, open, high, low, close, volume, adjclose)\n          VALUES (\n            '${data.date}',\n            ${data.open},\n            ${data.high},\n            ${data.low},\n            ${data.close},\n            ${data.volume},\n            ${data.adjclose}\n          )\n        `\n      });\n      insertStmt.execute();\n      return { status: 'inserted', date: data.date };\n    }\n  } catch (error) {\n    return { status: 'error', message: error.message };\n  }\n}\n$$;\n\n-- Grant necessary permissions\nGRANT USAGE ON PROCEDURE CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_DATA_SP() TO ROLE CRYPTO_ROLE;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell5",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- %%sql\nCREATE OR REPLACE TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK\n    WAREHOUSE = CRYPTO_WH\n    SCHEDULE = 'USING CRON 0 */4 * * * UTC'  -- Run every 4 hours\nAS\nCALL CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_DATA_SP();",
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "16e9403b-c418-43eb-a798-c006206f6a26",
   "metadata": {
    "language": "sql",
    "name": "cell29",
    "collapsed": false
   },
   "outputs": [],
   "source": "EXECUTE TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b74df39-34cd-4519-9cc2-b89b20dad520",
   "metadata": {
    "language": "sql",
    "name": "cell31",
    "collapsed": false
   },
   "outputs": [],
   "source": "SHOW TASKS LIKE 'LOAD_CRYPTO_TASK' IN SCHEMA CRYPTO_DB.HARMONIZED_CRYPTO;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5d3f3af-e169-47f4-bc98-9658e1bcc63f",
   "metadata": {
    "language": "sql",
    "name": "cell32"
   },
   "outputs": [],
   "source": "EXECUTE TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1c9601c-ef94-45fe-963f-13ba7b35c2fc",
   "metadata": {
    "language": "sql",
    "name": "cell33"
   },
   "outputs": [],
   "source": "SELECT *\nFROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n    SCHEDULED_TIME_RANGE_START=>DATEADD('MINUTE',-10,CURRENT_TIMESTAMP()),\n    RESULT_LIMIT => 10))\nWHERE NAME = 'LOAD_CRYPTO_TASK'\nORDER BY SCHEDULED_TIME DESC;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell6"
   },
   "source": [
    "### 2. Create Task for Data Harmonization - Triggered when new data arrives"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell7",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- %%sql\nCREATE OR REPLACE TASK CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK\n    WAREHOUSE = CRYPTO_WH\n    AFTER CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK\n    WHEN SYSTEM$STREAM_HAS_DATA('CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM')\nAS\nCALL CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_DATA_SP();",
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell8"
   },
   "source": [
    "### 3. Create Task to Update Analytics Tables - Runs after harmonization completes"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell9",
    "language": "sql",
    "collapsed": false
   },
   "source": "USE ROLE CRYPTO_ROLE;\nCREATE OR REPLACE TASK CRYPTO_DB.HARMONIZED_CRYPTO.UPDATE_CRYPTO_METRICS_TASK\n    WAREHOUSE = CRYPTO_WH\n    AFTER CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK\n    WHEN SYSTEM$STREAM_HAS_DATA('CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED_STREAM')\nAS\nCALL CRYPTO_DB.ANALYTICS_CRYPTO.UPDATE_CRYPTO_ANALYTICS();",
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell10"
   },
   "source": [
    "## Set Up Change Tracking with Streams\n",
    "\n",
    "Streams track changes in tables to trigger downstream processes only when new data exists."
   ],
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell11",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- Create a stream on the harmonized data for change tracking\nUSE ROLE CRYPTO_ROLE;\nCREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED_STREAM\nON TABLE CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED;",
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "35408c98-c701-4039-917e-b2f008c01903",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "SHOW TABLES IN SCHEMA CRYPTO_DB.HARMONIZED_CRYPTO;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell12",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- Create stream for BTC (already done)\nCREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM_BTC\nON TABLE CRYPTO_DB.RAW_CRYPTO.BTC;\n\n-- Create stream for ETH\nCREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM_ETH\nON TABLE CRYPTO_DB.RAW_CRYPTO.ETH;\n\n-- Create stream for DOGE\nCREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM_DOGE\nON TABLE CRYPTO_DB.RAW_CRYPTO.DOGE;",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell13"
   },
   "source": [
    "## Activate the Automation Pipeline\n",
    "\n",
    "Resume all tasks to start the automation workflow. Tasks are resumed in reverse order of their dependency chain."
   ],
   "id": "ce110000-1111-2222-3333-ffffff000012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell14",
    "language": "sql",
    "collapsed": false
   },
   "source": "-- %%sql\n-- %%sql\nALTER TASK CRYPTO_DB.HARMONIZED_CRYPTO.UPDATE_CRYPTO_METRICS_TASK RESUME;\nALTER TASK CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK RESUME;\nALTER TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK RESUME;",
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell15"
   },
   "source": [
    "## Task Monitoring and Observability\n",
    "\n",
    "### Check Recent Task Execution History"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell16",
    "language": "python",
    "collapsed": false
   },
   "source": [
    "task_history = session.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n",
    "    SCHEDULED_TIME_RANGE_START=>DATEADD('DAY',-1,CURRENT_TIMESTAMP()),\n",
    "    RESULT_LIMIT => 100))\n",
    "ORDER BY SCHEDULED_TIME DESC\n",
    "\"\"\")\n",
    "\n",
    "task_history.show()"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell17"
   },
   "source": [
    "### View Task Dependency Graph"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell18",
    "language": "sql",
    "collapsed": false
   },
   "source": "\nSELECT *\nFROM TABLE(INFORMATION_SCHEMA.CURRENT_TASK_GRAPHS())\nORDER BY SCHEDULED_TIME;",
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell19"
   },
   "source": [
    "## Create Pipeline Health Dashboard\n",
    "\n",
    "This dashboard view provides insights into both task performance and data freshness"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000018"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell20",
    "language": "sql",
    "collapsed": false
   },
   "source": "\nCREATE OR REPLACE VIEW CRYPTO_DB.ANALYTICS_CRYPTO.PIPELINE_HEALTH_DASHBOARD AS\nWITH task_stats AS (\n    SELECT\n        NAME as task_name,\n        COUNT(*) as total_runs,\n        SUM(CASE WHEN STATE = 'SUCCEEDED' THEN 1 ELSE 0 END) as successful_runs,\n        SUM(CASE WHEN STATE = 'FAILED' THEN 1 ELSE 0 END) as failed_runs,\n        MAX(CASE WHEN STATE = 'SUCCEEDED' THEN COMPLETED_TIME ELSE NULL END) as last_successful_run,\n        MAX(CASE WHEN STATE = 'FAILED' THEN COMPLETED_TIME ELSE NULL END) as last_failed_run,\n        AVG(CASE WHEN STATE = 'SUCCEEDED' THEN TIMESTAMPDIFF(MILLISECOND, QUERY_START_TIME, COMPLETED_TIME) ELSE NULL END) as avg_duration_ms\n    FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n        SCHEDULED_TIME_RANGE_START=>DATEADD('DAY',-7,CURRENT_TIMESTAMP())))\n    GROUP BY NAME\n),\ndata_stats AS (\n    SELECT\n        'BTC' as crypto_symbol,\n        COUNT(*) as record_count,\n        MIN(timestamp) as earliest_record,\n        MAX(timestamp) as latest_record,\n        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n    WHERE crypto_symbol = 'BTC'\n    UNION ALL\n    SELECT\n        'ETH' as crypto_symbol,\n        COUNT(*) as record_count,\n        MIN(timestamp) as earliest_record,\n        MAX(timestamp) as latest_record,\n        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n    WHERE crypto_symbol = 'ETH'\n    UNION ALL\n    SELECT\n        'DOGE' as crypto_symbol,\n        COUNT(*) as record_count,\n        MIN(timestamp) as earliest_record,\n        MAX(timestamp) as latest_record,\n        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n    WHERE crypto_symbol = 'DOGE'\n)\nSELECT\n    'Task Health' as metric_type,\n    task_name as metric_name,\n    total_runs,\n    successful_runs,\n    failed_runs,\n    ROUND(successful_runs/NULLIF(total_runs,0)*100, 2) as success_rate,\n    last_successful_run,\n    last_failed_run,\n    avg_duration_ms,\n    NULL as record_count,\n    NULL as earliest_record,\n    NULL as latest_record,\n    NULL as hours_since_last_update\nFROM task_stats\nUNION ALL\nSELECT\n    'Data Health' as metric_type,\n    crypto_symbol as metric_name,\n    NULL as total_runs,\n    NULL as successful_runs,\n    NULL as failed_runs,\n    NULL as success_rate,\n    NULL as last_successful_run,\n    NULL as last_failed_run,\n    NULL as avg_duration_ms,\n    record_count,\n    earliest_record,\n    latest_record,\n    hours_since_last_update\nFROM data_stats\nORDER BY metric_type, metric_name;",
   "id": "ce110000-1111-2222-3333-ffffff000019",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell21"
   },
   "source": [
    "### Check the Pipeline Health Dashboard"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000020"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell22",
    "language": "python",
    "collapsed": false
   },
   "source": "pipeline_health = session.sql(\"SELECT * FROM CRYPTO_DB.ANALYTICS_CRYPTO.PIPELINE_HEALTH_DASHBOARD\")\npipeline_health.show()",
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell23"
   },
   "source": [
    "## Set Up Alert Notifications\n",
    "\n",
    "Create email alerts that will notify administrators when tasks fail"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000022"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell24",
    "language": "sql",
    "collapsed": false
   },
   "source": "\n-- CREATE OR REPLACE NOTIFICATION INTEGRATION crypto_email_integration\n--   TYPE = EMAIL\n--   ENABLED = TRUE;\n\n-- CREATE OR REPLACE ALERT CRYPTO_DB.ANALYTICS_CRYPTO.TASK_FAILURE_ALERT\n--   WAREHOUSE = CRYPTO_WH\n--   SCHEDULE = 'USING CRON 0 */1 * * * UTC'  -- Check every hour\n--   IF (EXISTS (\n--     SELECT 1 \n--     FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n--       SCHEDULED_TIME_RANGE_START=>DATEADD('HOUR',-1,CURRENT_TIMESTAMP())))\n--     WHERE STATE = 'FAILED'\n--   ))\n--   THEN CALL SYSTEM$SEND_EMAIL(\n--     'crypto_email_integration',\n--     'admin@example.com',\n--     'Crypto Pipeline Task Failure Alert',\n--     'A task in the Crypto data pipeline has failed in the last hour. Please check the task history.'\n--   );\n\n-- -- Resume the alert to activate it\n-- ALTER ALERT CRYPTO_DB.ANALYTICS_CRYPTO.TASK_FAILURE_ALERT RESUME;",
   "id": "ce110000-1111-2222-3333-ffffff000023",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell25"
   },
   "source": [
    "## Pipeline Visualization\n",
    "\n",
    "The cryptocurrency data pipeline has the following task dependencies:\n",
    "\n",
    "```\n",
    "LOAD_CRYPTO_TASK (every 4 hours)\n",
    "       |\n",
    "       V\n",
    "HARMONIZE_CRYPTO_TASK (when RAW_CRYPTO_STREAM has data)\n",
    "       |\n",
    "       V\n",
    "UPDATE_CRYPTO_METRICS_TASK (when CRYPTO_HARMONIZED_STREAM has data)\n",
    "```\n",
    "\n",
    "This creates a fully automated workflow that processes data in stages:\n",
    "1. Ingest raw cryptocurrency data\n",
    "2. Transform and harmonize the data\n",
    "3. Calculate analytics and metrics\n",
    "\n",
    "Each step only runs when there is actual new data to process, optimizing resource usage."
   ],
   "id": "ce110000-1111-2222-3333-ffffff000024"
  }
 ]
}