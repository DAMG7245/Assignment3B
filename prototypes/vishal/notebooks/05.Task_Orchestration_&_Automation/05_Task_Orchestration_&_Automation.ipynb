{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptocurrency Data Pipeline - Task Orchestration & Automation\n",
    "\n",
    "This notebook implements the task orchestration layer for the cryptocurrency data pipeline, automating the flow from data ingestion through harmonization to analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "USE ROLE CRYPTO_ROLE;\n",
    "USE WAREHOUSE CRYPTO_WH;\n",
    "USE SCHEMA CRYPTO_DB.HARMONIZED_CRYPTO;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tasks for Pipeline Automation\n",
    "\n",
    "### 1. Data Ingestion Task - Runs every 4 hours to fetch new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK\n",
    "    WAREHOUSE = CRYPTO_WH\n",
    "    SCHEDULE = 'USING CRON 0 */4 * * * UTC'  -- Run every 4 hours\n",
    "AS\n",
    "CALL CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_DATA_SP();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Task for Data Harmonization - Triggered when new data arrives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TASK CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK\n",
    "    WAREHOUSE = CRYPTO_WH\n",
    "    AFTER CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK\n",
    "    WHEN SYSTEM$STREAM_HAS_DATA('CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM')\n",
    "AS\n",
    "CALL CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_DATA_SP();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Task to Update Analytics Tables - Runs after harmonization completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TASK CRYPTO_DB.ANALYTICS_CRYPTO.UPDATE_CRYPTO_METRICS_TASK\n",
    "    WAREHOUSE = CRYPTO_WH\n",
    "    AFTER CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK\n",
    "    WHEN SYSTEM$STREAM_HAS_DATA('CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED_STREAM')\n",
    "AS\n",
    "CALL CRYPTO_DB.ANALYTICS_CRYPTO.UPDATE_CRYPTO_ANALYTICS();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Change Tracking with Streams\n",
    "\n",
    "Streams track changes in tables to trigger downstream processes only when new data exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "-- Create a stream on the harmonized data for change tracking\n",
    "CREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED_STREAM\n",
    "ON TABLE CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "-- Create a stream on the raw data for change tracking\n",
    "CREATE OR REPLACE STREAM CRYPTO_DB.HARMONIZED_CRYPTO.RAW_CRYPTO_STREAM\n",
    "ON TABLE CRYPTO_DB.PUBLIC.BTC_RAW;  -- Assuming BTC_RAW is your raw data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the Automation Pipeline\n",
    "\n",
    "Resume all tasks to start the automation workflow. Tasks are resumed in reverse order of their dependency chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "ALTER TASK CRYPTO_DB.ANALYTICS_CRYPTO.UPDATE_CRYPTO_METRICS_TASK RESUME;\n",
    "ALTER TASK CRYPTO_DB.HARMONIZED_CRYPTO.HARMONIZE_CRYPTO_TASK RESUME;\n",
    "ALTER TASK CRYPTO_DB.HARMONIZED_CRYPTO.LOAD_CRYPTO_TASK RESUME;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Monitoring and Observability\n",
    "\n",
    "### Check Recent Task Execution History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "task_history = session.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n",
    "    SCHEDULED_TIME_RANGE_START=>DATEADD('DAY',-1,CURRENT_TIMESTAMP()),\n",
    "    RESULT_LIMIT => 100))\n",
    "ORDER BY SCHEDULED_TIME DESC\n",
    "\"\"\")\n",
    "\n",
    "task_history.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Task Dependency Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM TABLE(INFORMATION_SCHEMA.CURRENT_TASK_GRAPHS())\n",
    "ORDER BY SCHEDULED_TIME;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline Health Dashboard\n",
    "\n",
    "This dashboard view provides insights into both task performance and data freshness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE VIEW CRYPTO_DB.ANALYTICS_CRYPTO.PIPELINE_HEALTH_DASHBOARD AS\n",
    "WITH task_stats AS (\n",
    "    SELECT\n",
    "        NAME as task_name,\n",
    "        COUNT(*) as total_runs,\n",
    "        SUM(CASE WHEN STATE = 'SUCCEEDED' THEN 1 ELSE 0 END) as successful_runs,\n",
    "        SUM(CASE WHEN STATE = 'FAILED' THEN 1 ELSE 0 END) as failed_runs,\n",
    "        MAX(CASE WHEN STATE = 'SUCCEEDED' THEN COMPLETED_TIME ELSE NULL END) as last_successful_run,\n",
    "        MAX(CASE WHEN STATE = 'FAILED' THEN COMPLETED_TIME ELSE NULL END) as last_failed_run,\n",
    "        AVG(CASE WHEN STATE = 'SUCCEEDED' THEN TIMESTAMPDIFF(MILLISECOND, QUERY_START_TIME, COMPLETED_TIME) ELSE NULL END) as avg_duration_ms\n",
    "    FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n",
    "        SCHEDULED_TIME_RANGE_START=>DATEADD('DAY',-7,CURRENT_TIMESTAMP())))\n",
    "    GROUP BY NAME\n",
    "),\n",
    "data_stats AS (\n",
    "    SELECT\n",
    "        'BTC' as crypto_symbol,\n",
    "        COUNT(*) as record_count,\n",
    "        MIN(timestamp) as earliest_record,\n",
    "        MAX(timestamp) as latest_record,\n",
    "        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n",
    "    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n",
    "    WHERE crypto_symbol = 'BTC'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'ETH' as crypto_symbol,\n",
    "        COUNT(*) as record_count,\n",
    "        MIN(timestamp) as earliest_record,\n",
    "        MAX(timestamp) as latest_record,\n",
    "        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n",
    "    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n",
    "    WHERE crypto_symbol = 'ETH'\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'DOGE' as crypto_symbol,\n",
    "        COUNT(*) as record_count,\n",
    "        MIN(timestamp) as earliest_record,\n",
    "        MAX(timestamp) as latest_record,\n",
    "        DATEDIFF('hour', MAX(timestamp), CURRENT_TIMESTAMP()) as hours_since_last_update\n",
    "    FROM CRYPTO_DB.HARMONIZED_CRYPTO.CRYPTO_HARMONIZED\n",
    "    WHERE crypto_symbol = 'DOGE'\n",
    ")\n",
    "SELECT\n",
    "    'Task Health' as metric_type,\n",
    "    task_name as metric_name,\n",
    "    total_runs,\n",
    "    successful_runs,\n",
    "    failed_runs,\n",
    "    ROUND(successful_runs/NULLIF(total_runs,0)*100, 2) as success_rate,\n",
    "    last_successful_run,\n",
    "    last_failed_run,\n",
    "    avg_duration_ms,\n",
    "    NULL as record_count,\n",
    "    NULL as earliest_record,\n",
    "    NULL as latest_record,\n",
    "    NULL as hours_since_last_update\n",
    "FROM task_stats\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'Data Health' as metric_type,\n",
    "    crypto_symbol as metric_name,\n",
    "    NULL as total_runs,\n",
    "    NULL as successful_runs,\n",
    "    NULL as failed_runs,\n",
    "    NULL as success_rate,\n",
    "    NULL as last_successful_run,\n",
    "    NULL as last_failed_run,\n",
    "    NULL as avg_duration_ms,\n",
    "    record_count,\n",
    "    earliest_record,\n",
    "    latest_record,\n",
    "    hours_since_last_update\n",
    "FROM data_stats\n",
    "ORDER BY metric_type, metric_name;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Pipeline Health Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "pipeline_health = session.sql(\"SELECT * FROM CRYPTO_DB.ANALYTICS_CRYPTO.PIPELINE_HEALTH_DASHBOARD\")\n",
    "pipeline_health.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Alert Notifications\n",
    "\n",
    "Create email alerts that will notify administrators when tasks fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE NOTIFICATION INTEGRATION crypto_email_integration\n",
    "  TYPE = EMAIL\n",
    "  ENABLED = TRUE;\n",
    "\n",
    "CREATE OR REPLACE ALERT CRYPTO_DB.ANALYTICS_CRYPTO.TASK_FAILURE_ALERT\n",
    "  WAREHOUSE = CRYPTO_WH\n",
    "  SCHEDULE = 'USING CRON 0 */1 * * * UTC'  -- Check every hour\n",
    "  IF (EXISTS (\n",
    "    SELECT 1 \n",
    "    FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(\n",
    "      SCHEDULED_TIME_RANGE_START=>DATEADD('HOUR',-1,CURRENT_TIMESTAMP())))\n",
    "    WHERE STATE = 'FAILED'\n",
    "  ))\n",
    "  THEN CALL SYSTEM$SEND_EMAIL(\n",
    "    'crypto_email_integration',\n",
    "    'admin@example.com',\n",
    "    'Crypto Pipeline Task Failure Alert',\n",
    "    'A task in the Crypto data pipeline has failed in the last hour. Please check the task history.'\n",
    "  );\n",
    "\n",
    "-- Resume the alert to activate it\n",
    "ALTER ALERT CRYPTO_DB.ANALYTICS_CRYPTO.TASK_FAILURE_ALERT RESUME;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Visualization\n",
    "\n",
    "The cryptocurrency data pipeline has the following task dependencies:\n",
    "\n",
    "```\n",
    "LOAD_CRYPTO_TASK (every 4 hours)\n",
    "       |\n",
    "       V\n",
    "HARMONIZE_CRYPTO_TASK (when RAW_CRYPTO_STREAM has data)\n",
    "       |\n",
    "       V\n",
    "UPDATE_CRYPTO_METRICS_TASK (when CRYPTO_HARMONIZED_STREAM has data)\n",
    "```\n",
    "\n",
    "This creates a fully automated workflow that processes data in stages:\n",
    "1. Ingest raw cryptocurrency data\n",
    "2. Transform and harmonize the data\n",
    "3. Calculate analytics and metrics\n",
    "\n",
    "Each step only runs when there is actual new data to process, optimizing resource usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snowpark",
   "language": "python",
   "name": "snowpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}